{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemplos de uso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemplo de transferência de aprendizado utilizando PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos seguir o exemplo apresentado por Vasilev et al. (2019), que aplicou uma rede pré-treinada com ImageNet em imagens CIFAR-10.\n",
    "\n",
    "Inicialmente, vamos importar as bibliotecas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Importando biblioteca Torch e TorchVision***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import models, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida, vamos definir o tamanho do lote (batch_size):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Definindo tamanho do lote***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para definir o conjunto de dados de treinamento, vamos levar em consideração que as imagens CIFAR-10 têm tamanho 32x32, enquanto as redes ImageNet necessitam de dados de tamanho 224x224. \n",
    "\n",
    "Então, vamos aumentar as imagens do CIFAR-10 de 32x32 para 224x224. \n",
    "\n",
    "É necessário padronizar os dados do CIFAR-10 utilizando a média e o desvio-padrão da ImageNet, e é necessário adicionar um pequeno aumento de dados (flip):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Definindo dados de treinamento***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Dados de Treinamento\n",
    "train_data_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_data_transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizar os seguintes passos com os dados de validação e teste:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "val_data_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=val_data_transform)\n",
    "\n",
    "val_order = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escolher um dispositivo, preferencialmente GPU:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir o modelo de treinamento. Ao contrário do Keras, com PyTorch é necessário realizar as repetições manualmente sobre os dados de treinamento.\n",
    "\n",
    "Este método repete uma vez por todo o conjunto de treinamento (uma iteração) e aplica um otimizador após cada passo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função de Treinamento do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, loss_function, optimizer, data_loader):\n",
    "    \n",
    "    # Definindo o modelo para o modo de treinamento\n",
    "    model.train()\n",
    "\n",
    "    current_loss = 0.0\n",
    "    current_acc = 0\n",
    "\n",
    "    # Repete sobre o conjunto de treinamento\n",
    "    for i, (inputs, labels) in enumerate(data_loader):\n",
    "        # Envia a entrada ou os rótulos para a GPU\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # reinicia os parâmetros do gradiente\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.set_grad_enabled(True):\n",
    "            # Passo adiante\n",
    "            outputs = model(inputs)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            loss = loss_function(outputs, labels)\n",
    "\n",
    "            # passo para trás\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Estatística\n",
    "        current_loss += loss.item() * inputs.size(0)\n",
    "        current_acc += torch.sum(predictions == labels.data)\n",
    "\n",
    "    total_loss = current_loss / len(data_loader.dataset)\n",
    "    total_acc = current_acc.double() / len(data_loader.dataset)\n",
    "\n",
    "    print('Train Loss: {:.4f}; Accuracy: {:.4f}'.format(total_loss, total_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função de Teste do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, loss_function, data_loader):\n",
    "\n",
    "    # Definindo o modelo para o modo de avaliacao\n",
    "    model.eval()\n",
    "    current_loss = 0.0\n",
    "    current_acc = 0\n",
    "    \n",
    "     # Repete sobre o conjunto de validação\n",
    "    for i, (inputs, labels) in enumerate(data_loader):\n",
    "        # Envia a entrada ou os rótulos para a GPU\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Passo adiante\n",
    "        with torch.set_grad_enabled(False):\n",
    "            outputs = model(inputs)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            \n",
    "        # Estatistica\n",
    "        current_loss += loss.item() * inputs.size(0)\n",
    "        current_acc += torch.sum(predictions == labels.data)\n",
    "        \n",
    "    total_loss = current_loss / len(data_loader.dataset)\n",
    "    total_acc = current_acc.double() / len(data_loader.dataset)\n",
    "    print('Test Loss: {:.4f}; Accuracy: {:.4f}'.format(total_loss, total_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir o primeiro cenário de transferência de aprendizado, em que a rede pré-treinada é utilizada como extratora de características. \n",
    "\n",
    "Será utilizada uma rede popular, chamada ResNet-18, e o PyTorch fará o download dos pesos prétreinados automaticamente. Vamos substituir a última camada da rede por uma nova camada com 10 classes de saída (uma para cada classe do CIFAR-10). \n",
    "\n",
    "Vamos eliminar as camadas da rede original do passo para trás, e atualizar os pesos apenas da camada adicionada utilizando o otimizador ADAM. \n",
    "\n",
    "Vamos rodar o treinamento e verificar a acurácia da rede a cada iteração:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função de extração de características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tl_feature_extractor(epochs=3):\n",
    "    # Carregar o modelo pré-treinado\n",
    "    model = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "    # Excluir os parâmetros existentes do passo para trás\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # As novas camadas require, por padrão,\n",
    "    # requires_grad=True\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_features, 10)\n",
    "\n",
    "    # Transferindo para a GPU (se disponível)\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Otimizar apenas os parâmetros da última camada\n",
    "    optimizer = optim.Adam(model.fc.parameters())\n",
    "    \n",
    "    # treinamento\n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch {}/{}'.format(epoch + 1, epochs))\n",
    "    \n",
    "    train_model(model, loss_function, optimizer, train_loader)\n",
    "    test_model(model, loss_function, val_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir o segundo cenário para refinamento da rede original. Similar ao cenário anterior, porém, toda a rede será treinada novamente:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função de Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tl_fine_tuning(epochs=3):\n",
    "    # Carregar o modelo pré-treinado\n",
    "    model = models.resnet18(pretrained=True)\n",
    "\n",
    "    # Substituir a última camada\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_features, 10)\n",
    "\n",
    "    # Transferir o modelo para a GPU\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Função de Perda\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Otimização de todos os parâmetros\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "    # treinamento\n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch {}/{}'.format(epoch + 1, epochs))\n",
    "\n",
    "    train_model(model, loss_function, optimizer,train_loader)\n",
    "    test_model(model, loss_function, val_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível rodar a rede de acordo com o cenário escolhido. \n",
    "\n",
    "I. chamar a função tl_feature_extractor(epochs=5);\n",
    "\n",
    "II. chamar a função tl_fine_tuning(epochs=5)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chamando primeira função"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "Epoch 2/5\n",
      "Epoch 3/5\n",
      "Epoch 4/5\n",
      "Epoch 5/5\n",
      "Train Loss: 1.0513; Accuracy: 0.6421\n",
      "Test Loss: 0.7255; Accuracy: 0.7528\n"
     ]
    }
   ],
   "source": [
    "tl_feature_extractor(epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chamando segunda função"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "Epoch 2/5\n",
      "Epoch 3/5\n",
      "Epoch 4/5\n",
      "Epoch 5/5\n",
      "Train Loss: 0.8023; Accuracy: 0.7211\n",
      "Test Loss: 0.7507; Accuracy: 0.7471\n"
     ]
    }
   ],
   "source": [
    "tl_fine_tuning(epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para o primeiro cenário, a acurácia obtida foi de 64%, enquanto, no segundo cenário, a acurácia foi de 72%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
